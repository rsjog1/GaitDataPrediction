{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import utils"
      ],
      "metadata": {
        "id": "7wwXRbe3DJlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lM2Ii3T1mQha"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import importlib\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats as st\n",
        "import random\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dL-DKWOlTsfo"
      },
      "outputs": [],
      "source": [
        "def loadFeatures(dataFolder,winSz,timeStep,idList):\n",
        "  for k,id in enumerate(idList):\n",
        "    # Loading the raw data\n",
        "    xt, xv, yt, yv = utils.loadTrial(dataFolder,id=id)\n",
        "\n",
        "    # Extracting the time window for which we have values for the measurements and the response\n",
        "    timeStart = np.max((np.min(xt),np.min(yt)))\n",
        "    timeEnd = np.min((np.max(xt),np.max(yt)))\n",
        "\n",
        "    # Extracting the features\n",
        "    _, feat = utils.extractFeat(xt,xv,winSz,timeStart,timeEnd,timeStep)\n",
        "    _, lab = utils.extractLabel(yt,yv,winSz,timeStart,timeEnd,timeStep)\n",
        "\n",
        "    # Storing the features\n",
        "    if(k==0):\n",
        "      featList = feat\n",
        "      labList = lab\n",
        "    else:\n",
        "      featList = np.concatenate((featList,feat),axis=0)\n",
        "      labList = np.concatenate((labList,lab),axis=0)\n",
        "\n",
        "  return featList, labList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfZKGP22SmvP"
      },
      "outputs": [],
      "source": [
        "dirTrain = \"data/train/\"\n",
        "\n",
        "timeStep = 1\n",
        "winSz = 2\n",
        "\n",
        "valIDs = []\n",
        "while len(valIDs) < 3:\n",
        "  num = random.randint(1, 26)\n",
        "  if num != 7 and num not in valIDs:\n",
        "    valIDs.append(num)\n",
        "\n",
        "trainIDs = list(set(np.array(range(25))+1).difference(valIDs))\n",
        "\n",
        "xTrain, yTrain = loadFeatures(dirTrain,winSz,timeStep,trainIDs)\n",
        "xVal , yVal = loadFeatures(dirTrain, winSz, timeStep, valIDs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "class NetWrapperCNN:\n",
        "    def __init__(self, model, device, epochs, weights):\n",
        "        self.device = device\n",
        "        self.model = model.to(device)  # Move model to the specified device\n",
        "        weight_tensor = torch.tensor(weights, dtype=torch.float).to(device)  # Ensure weights are on the GPU\n",
        "        self.loss_fn = nn.CrossEntropyLoss(weight=weight_tensor)\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        if X.ndim == 2:\n",
        "            X = np.expand_dims(X, axis=-1)  # Add a channel dimension if it's not present\n",
        "\n",
        "        X = torch.from_numpy(X).float().permute(0, 2, 1).to(self.device)  # Move to GPU after conversion\n",
        "        y = torch.from_numpy(y).long().to(self.device)  # Ensure labels are also on GPU\n",
        "\n",
        "        for t in range(self.epochs):\n",
        "            self.optimizer.zero_grad()\n",
        "            pred = self.model(X)\n",
        "            loss = self.loss_fn(pred, y)\n",
        "\n",
        "            if torch.isnan(loss):\n",
        "                print(\"Loss is NaN\")\n",
        "                break\n",
        "\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            if t % 500 == 499:\n",
        "                print(f\"Epoch {t+1}, Loss: {loss.item()}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        if X.ndim == 2:\n",
        "            X = np.expand_dims(X, axis=-1)\n",
        "\n",
        "        X = torch.from_numpy(X).float().permute(0, 2, 1).to(self.device)  # Adjust and move data\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            pred = self.model(X)\n",
        "            pred = pred.cpu().detach().numpy()\n",
        "            pred = np.argmax(pred, axis=1)\n",
        "\n",
        "        return pred\n",
        "\n",
        "\n",
        "\n",
        "INPUTSIZE = 12\n",
        "OUTPUTSIZE = 4\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "EPOCHS = 7500\n",
        "\n",
        "WEIGHTS = [0.20306067974248987, 0.9514893558595908, 0.6781497198149791, 0.8505315580874674]\n"
      ],
      "metadata": {
        "id": "qMgh1SriiEAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(DEVICE)"
      ],
      "metadata": {
        "id": "HzrIs-43kSVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QZp2tpgcoAR"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self, input_size, output_size):\n",
        "    super(CNN, self).__init__()\n",
        "    self.conv1 = nn.Conv1d(input_size, 128, 1)\n",
        "    self.conv2 = nn.Conv1d(128, 256, 1)\n",
        "    self.fc2 = nn.Linear(256, 64)\n",
        "    self.fc3 = nn.Linear(64, output_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    # self.dropout = nn.Dropout(0.5)\n",
        "    self.maxpool = nn.MaxPool1d(2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.relu(self.conv1(x))\n",
        "    x = self.maxpool(x)\n",
        "    x = self.relu(self.conv2(x))\n",
        "    # x = self.maxpool(x)\n",
        "    # x = self.relu(self.conv3(x))\n",
        "    x = torch.mean(x, dim=2)  # Global average pooling\n",
        "    x = self.relu(self.fc2(x))\n",
        "    # x = self.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIOTEO6JlR6b"
      },
      "outputs": [],
      "source": [
        "cnn_model = CNN(input_size=1, output_size=OUTPUTSIZE)\n",
        "net_cnn = NetWrapperCNN(model=cnn_model, device=DEVICE, epochs=EPOCHS, weights=WEIGHTS)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net_cnn.fit(xTrain, yTrain)"
      ],
      "metadata": {
        "id": "45Sz7ESqi_uG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yTrainHat = net_cnn.predict(xTrain)\n",
        "yValHat = net_cnn.predict(xVal)\n",
        "\n",
        "print('Results for Validation:\\n')\n",
        "utils.summaryPerf(yVal,yValHat,yTrain,yTrainHat)"
      ],
      "metadata": {
        "id": "Dl2685yZjR1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getUpdatedPreds(xt, yt, yValHat):\n",
        "  yPreds = []\n",
        "  for i in yt:\n",
        "    win = np.where((xt>=i-0.1)*(xt<=i+0.1))\n",
        "    # print(win)\n",
        "\n",
        "    wnd = []\n",
        "    for j in win[0]:\n",
        "      if j < len(yValHat):\n",
        "        wnd.append(j)\n",
        "    if len(wnd) == 0:\n",
        "      yPreds.append(st.mode(yWin).mode)\n",
        "      # yPreds.append(np.max(yWin))\n",
        "    else:\n",
        "      yWin = yValHat[wnd]\n",
        "      yPreds.append(st.mode(yWin).mode)\n",
        "      # yPreds.append(np.max(yWin))\n",
        "\n",
        "  return np.array(yPreds)"
      ],
      "metadata": {
        "id": "U_WnaABW44Gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Npbk-Juc44HI"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "dirTest = \"data/test/\"\n",
        "for id in [1,2,3,4]:\n",
        "  xt, xv, yt, yv = utils.loadTrial(dirTrain,id)\n",
        "  timeStart = np.max((np.min(xt),np.min(yt)))\n",
        "  timeEnd = np.min((np.max(xt),np.max(yt)))\n",
        "  _, xVal = utils.extractFeat(xt,xv,winSz,timeStart,timeEnd,0.025)\n",
        "  yValHat = net_cnn.predict(xVal)\n",
        "  yPreds = getUpdatedPreds(xt, yt, yValHat)\n",
        "  print(\"Unique Values:\", np.unique(yPreds, return_counts=True), np.unique(yv, return_counts=True))\n",
        "  print(\"Balanced Accuracy Score for trial\", id, \":\", balanced_accuracy_score(yv, yPreds))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}